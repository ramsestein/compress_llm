# üéØ Ejemplos Pr√°cticos - Compress LLM

## üìö Casos de Uso Comunes

### üéØ Ejemplo 1: Comprimir un Modelo Grande

**Situaci√≥n**: Tienes un modelo de 7GB y quieres reducirlo a 2GB

```bash
# 1. Descargar un modelo de ejemplo
python -c "
from transformers import AutoModelForCausalLM, AutoTokenizer
model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')
tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')
model.save_pretrained('./models/dialogpt_original')
tokenizer.save_pretrained('./models/dialogpt_original')
"

# 2. Comprimir el modelo
python apply_compression.py --model_path "./models/dialogpt_original" --output_path "./models/dialogpt_comprimido"

# 3. Verificar la compresi√≥n
python verify_compression.py --model_path "./models/dialogpt_comprimido"
```

**Resultado**: Modelo reducido de ~1.5GB a ~400MB

---

### üéØ Ejemplo 2: Mejorar un Modelo con LoRA

**Situaci√≥n**: Quieres que el modelo sea mejor en espa√±ol

```bash
# 1. Preparar datos en espa√±ol (archivo CSV)
# Crear archivo: datasets/espanol.csv
# Formato: text,response
# Ejemplo:
# "Hola, ¬øc√≥mo est√°s?", "¬°Hola! Estoy muy bien, ¬øy t√∫?"

# 2. Ejecutar fine-tuning
python finetune_peft.py

# 3. Seguir las instrucciones:
# - Seleccionar: LoRA
# - Modelo: microsoft/DialoGPT-small
# - Datos: datasets/espanol.csv
# - √âpocas: 3
# - Learning rate: 2e-4
```

**Resultado**: Modelo mejorado para espa√±ol con solo 10MB adicionales

---

### üéØ Ejemplo 3: Optimizar para Poca Memoria

**Situaci√≥n**: Solo tienes 8GB de RAM

```bash
# 1. Usar QLoRA (cuantizaci√≥n + LoRA)
python finetune_peft.py

# 2. Configuraci√≥n recomendada:
# - M√©todo: QLoRA
# - Bits: 4
# - Rank: 8
# - Batch size: 1
# - Gradient accumulation: 4
```

**Resultado**: Entrenamiento posible en 8GB de RAM

---

### üéØ Ejemplo 4: Crear un Chatbot Personalizado

**Situaci√≥n**: Quieres un chatbot para tu empresa

```bash
# 1. Preparar datos de conversaciones
# Crear: datasets/chatbot_empresa.csv
# Formato: 
# "¬øCu√°l es el horario de atenci√≥n?", "Nuestro horario es de 9:00 a 18:00"
# "¬øTienen env√≠o gratis?", "S√≠, env√≠o gratis en compras superiores a $50"

# 2. Entrenar con IA3 (muy r√°pido)
python finetune_peft.py
# - M√©todo: IA3
# - √âpocas: 1
# - Learning rate: 1e-3

# 3. Probar el modelo
python test_compressed_model.py --model_path "./finetuned_models/mi_chatbot"
```

**Resultado**: Chatbot personalizado en 30 minutos

---

### üéØ Ejemplo 5: Servidor de Modelos

**Situaci√≥n**: Quieres servir modelos a trav√©s de API

```bash
# 1. Iniciar servidor
python ollama_compact_server.py --models_dir "./models"

# 2. El servidor estar√° disponible en:
# http://localhost:8000

# 3. Usar con curl:
curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{"model": "dialogpt_comprimido", "prompt": "Hola, ¬øc√≥mo est√°s?"}'
```

**Resultado**: API REST para tus modelos

---

## üìä Comparaci√≥n de M√©todos

| M√©todo | Velocidad | Memoria | Calidad | Uso Recomendado |
|--------|-----------|---------|---------|-----------------|
| **LoRA** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | General |
| **IA3** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | R√°pido |
| **BitFit** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Muy limitado |
| **QLoRA** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Poca memoria |
| **DoRA** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | M√°xima calidad |

---

## üîß Configuraciones Recomendadas

### Para Principiantes:
```bash
python finetune_peft.py
# - M√©todo: LoRA
# - Rank: 16
# - Alpha: 32
# - √âpocas: 3
# - Learning rate: 2e-4
```

### Para Experiencia Media:
```bash
python finetune_peft.py
# - M√©todo: QLoRA
# - Bits: 4
# - Rank: 32
# - √âpocas: 5
# - Learning rate: 1e-4
```

### Para Expertos:
```bash
python finetune_peft.py
# - M√©todo: DoRA
# - Rank: 64
# - Alpha: 128
# - √âpocas: 10
# - Learning rate: 5e-5
```

---

## üìà Monitoreo del Progreso

### Durante el Entrenamiento:
- **Loss**: Debe disminuir (ej: 2.5 ‚Üí 1.2)
- **Accuracy**: Debe aumentar (ej: 0.3 ‚Üí 0.8)
- **Memory**: No debe exceder tu RAM disponible

### M√©tricas Esperadas:
- **LoRA**: Loss < 1.5 despu√©s de 3 √©pocas
- **IA3**: Loss < 2.0 despu√©s de 1 √©poca
- **QLoRA**: Loss < 1.8 despu√©s de 5 √©pocas

---

## üö® Problemas Comunes y Soluciones

### Error: "CUDA out of memory"
```bash
# Soluci√≥n: Reducir batch size
python finetune_peft.py
# - Batch size: 1
# - Gradient accumulation: 8
```

### Error: "Model too large"
```bash
# Soluci√≥n: Usar compresi√≥n primero
python apply_compression.py --model_path "modelo_grande" --output_path "modelo_peque√±o"
```

### Error: "No convergence"
```bash
# Soluci√≥n: Ajustar learning rate
python finetune_peft.py
# - Learning rate: 1e-5 (m√°s bajo)
# - √âpocas: 10 (m√°s tiempo)
```

---

## üéâ ¬°√âxito!

Cuando veas estos mensajes, todo est√° funcionando:

```
‚úÖ Modelo comprimido exitosamente
‚úÖ Entrenamiento completado
‚úÖ Modelo guardado en: ./finetuned_models/
‚úÖ P√©rdida final: 1.234
‚úÖ Precisi√≥n final: 0.856
```

**¬°Tu modelo est√° listo para usar! üöÄ**
